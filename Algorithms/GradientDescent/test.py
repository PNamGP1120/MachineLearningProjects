import numpy as np
import matplotlib.pyplot as plt

from Algorithms.GradientDescent.GD import GradientDescent, MiniBatchGradientDescent, MomentumGradientDescent, \
    NesterovAcceleratedGradient, MultivariableGradientDescent


def cost(x):
    """H√†m m·∫•t m√°t: f(x) = x^2 + 5*sin(x)."""
    return x ** 2 + 5 * np.sin(x)


def grad(x):
    """ƒê·∫°o h√†m c·ªßa h√†m m·∫•t m√°t: f'(x) = 2x + 5cos(x)."""
    return 2 * x + 5 * np.cos(x)


def test_gradient_descent():
    """
    Ki·ªÉm tra hi·ªáu su·∫•t c·ªßa c√°c thu·∫≠t to√°n Gradient Descent.

    - Ch·∫°y t·ª´ng thu·∫≠t to√°n v·ªõi c√πng ƒëi·ªÅu ki·ªán ban ƒë·∫ßu.
    - Hi·ªÉn th·ªã s·ªë v√≤ng l·∫∑p c·∫ßn thi·∫øt ƒë·ªÉ h·ªôi t·ª•.
    - V·∫Ω ƒë·ªì th·ªã qu√° tr√¨nh t·ªëi ∆∞u h√≥a.
    """

    # Thi·∫øt l·∫≠p th√¥ng s·ªë
    x0 = -5  # Gi√° tr·ªã kh·ªüi t·∫°o
    eta = 0.01  # Learning rate
    gamma = 0.9  # H·ªá s·ªë Momentum
    batch_size = 100  # K√≠ch th∆∞·ªõc batch cho Mini-Batch GD
    tol = 1e-6  # Ng∆∞·ª°ng h·ªôi t·ª•

    # Kh·ªüi t·∫°o danh s√°ch thu·∫≠t to√°n
    algorithms = {
        "GD": GradientDescent(cost, grad, eta, tol),
        "Multivariable GD": MultivariableGradientDescent(cost, grad, eta, tol),
        "Mini-Batch GD": MiniBatchGradientDescent(cost, grad, eta, batch_size, tol),
        "Momentum GD": MomentumGradientDescent(cost, grad, eta, gamma, tol),
        "NAG": NesterovAcceleratedGradient(cost, grad, eta, gamma, tol)
    }

    results = {}

    # V·∫Ω ƒë·ªì th·ªã
    plt.figure(figsize=(10, 6))
    markers = ['o', 's', 'D', '^', 'x']
    colors = ['b', 'g', 'r', 'c', 'm']

    for i, (name, algo) in enumerate(algorithms.items()):
        x_values, iterations = algo.optimize(x0)
        y_values = [cost(x) for x in x_values]

        results[name] = {
            "iterations": iterations,
            "x_min": x_values[-1],
            "f_min": cost(x_values[-1])
        }

        plt.plot(range(len(y_values)), y_values, label=f"{name} ({iterations} iter)",
                 marker=markers[i], color=colors[i], linestyle='-')

    # C·∫•u h√¨nh bi·ªÉu ƒë·ªì
    plt.xlabel("S·ªë v√≤ng l·∫∑p")
    plt.ylabel("Gi√° tr·ªã h√†m m·∫•t m√°t")
    plt.title("So s√°nh c√°c thu·∫≠t to√°n Gradient Descent")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    print("\nüìä **K·∫øt qu·∫£ chi ti·∫øt:**")
    print(f"{'Thu·∫≠t to√°n':<25} {'S·ªë v√≤ng l·∫∑p':<15} {'x_min':<15} {'f_min':<15}")
    print("=" * 70)

    for name, res in results.items():
        print(f"{name:<25} {res['iterations']:<15} {res['x_min']:<15.6f} {res['f_min']:<15.6f}")


# Ch·∫°y ki·ªÉm th·ª≠
test_gradient_descent()
